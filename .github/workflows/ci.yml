name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:  # Allow manual triggering

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # Job 1: Code Quality Checks
  code-quality:
    name: Code Quality
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
        cache-dependency-path: requirements.txt
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Check import sorting with isort
      run: |
        isort --check-only --diff .
        
    - name: Check code formatting with ruff format
      run: |
        ruff format --check --diff .
        
    - name: Lint with ruff
      run: |
        ruff check --output-format=github .

  # Job 2: Security Checks
  security:
    name: Security Scan
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
        cache-dependency-path: requirements.txt
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install bandit[toml] safety
        
    - name: Run Bandit security linter
      run: |
        bandit -r ip_monitor/ -f json -o bandit-report.json || true
        bandit -r ip_monitor/ -f txt
        
    - name: Check for known vulnerabilities with Safety
      run: |
        safety check --json --output safety-report.json || true
        safety check
        
    - name: Upload security reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json
        retention-days: 30

  # Job 3: Test Matrix
  test:
    name: Test (Python ${{ matrix.python-version }}, ${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    timeout-minutes: 20
    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.11', '3.12', '3.13']
        os: [ubuntu-latest, windows-latest, macos-latest]
        exclude:
          # Reduce matrix size for faster builds - exclude some combinations
          - os: windows-latest
            python-version: '3.12'
          - os: macos-latest
            python-version: '3.12'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'
        cache-dependency-path: requirements.txt
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Run tests with coverage
      run: |
        pytest --cov=ip_monitor --cov-report=xml --cov-report=html --cov-report=term-missing -v
        
    - name: Upload coverage reports to Codecov
      uses: codecov/codecov-action@v4
      if: matrix.python-version == '3.11' && matrix.os == 'ubuntu-latest'
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false
        
    - name: Upload coverage HTML report
      uses: actions/upload-artifact@v4
      if: matrix.python-version == '3.11' && matrix.os == 'ubuntu-latest'
      with:
        name: coverage-report-html
        path: htmlcov/
        retention-days: 30
        
    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results-${{ matrix.python-version }}-${{ matrix.os }}
        path: |
          coverage.xml
          .coverage
        retention-days: 30

  # Job 4: Integration Tests
  integration-test:
    name: Integration Tests
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: [code-quality]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
        cache-dependency-path: requirements.txt
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Run integration tests
      run: |
        pytest tests/integration/ -v --tb=short
        
    - name: Run end-to-end admin command flow test
      run: |
        pytest tests/integration/test_admin_command_router.py::TestAdminCommandRouterIntegration::test_end_to_end_command_flow -v

  # Job 5: Performance Tests
  performance:
    name: Performance Tests
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: [test]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
        cache-dependency-path: requirements.txt
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest-benchmark
        
    - name: Run performance benchmarks
      run: |
        # Run a subset of tests with timing
        pytest tests/unit/commands/admin_commands/test_base_handler.py -v --tb=short --durations=10
        
    - name: Test async rate limiter performance
      run: |
        python -c "
        import asyncio
        import time
        from ip_monitor.utils.async_rate_limiter import AsyncRateLimiter
        
        async def test_rate_limiter_performance():
            limiter = AsyncRateLimiter(period=60, max_calls=100)
            
            start_time = time.time()
            tasks = []
            for _ in range(50):
                tasks.append(limiter.try_acquire())
            
            results = await asyncio.gather(*tasks)
            end_time = time.time()
            
            successful = sum(results)
            print(f'Rate limiter performance: {successful}/50 successful acquisitions in {end_time - start_time:.3f}s')
            assert successful > 0, 'Rate limiter should allow some acquisitions'
            
        asyncio.run(test_rate_limiter_performance())
        "

  # Job 6: Build validation
  build:
    name: Build Validation
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: [code-quality, security]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
        cache-dependency-path: requirements.txt
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Validate imports and syntax
      run: |
        python -m py_compile main.py
        python -c "import ip_monitor; print('✓ Package imports successfully')"
        
    - name: Check for missing dependencies
      run: |
        python -c "
        import pkg_resources
        import sys
        
        def check_dependencies():
            try:
                with open('requirements.txt', 'r') as f:
                    requirements = f.read().splitlines()
                
                # Filter out comments and empty lines
                requirements = [req.strip() for req in requirements if req.strip() and not req.strip().startswith('#')]
                
                for requirement in requirements:
                    try:
                        pkg_resources.require(requirement)
                        print(f'✓ {requirement}')
                    except pkg_resources.DistributionNotFound:
                        print(f'✗ Missing: {requirement}')
                        sys.exit(1)
                    except pkg_resources.VersionConflict as e:
                        print(f'✗ Version conflict: {e}')
                        sys.exit(1)
                
                print('✓ All dependencies satisfied')
            except Exception as e:
                print(f'Error checking dependencies: {e}')
                sys.exit(1)
        
        check_dependencies()
        "
        
    - name: Test bot initialization (dry run)
      run: |
        python -c "
        import os
        import sys
        from unittest.mock import patch
        
        # Mock environment variables for testing
        test_env = {
            'DISCORD_BOT_TOKEN': 'test_token',
            'CHANNEL_ID': '123456789',
            'DB_FILE': 'test.db',
            'TESTING_MODE': 'true'
        }
        
        with patch.dict(os.environ, test_env):
            try:
                from ip_monitor.config import AppConfig
                config = AppConfig()
                print('✓ Configuration loaded successfully')
                print(f'  - Check interval: {config.check_interval}')
                print(f'  - Testing mode: {config.testing_mode}')
            except Exception as e:
                print(f'✗ Configuration loading failed: {e}')
                sys.exit(1)
        "

  # Job 7: Documentation and Changelog Check
  docs:
    name: Documentation
    runs-on: ubuntu-latest
    timeout-minutes: 5
    if: github.event_name == 'pull_request'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Need full history for changed files
        
    - name: Check for documentation updates
      run: |
        # Get list of changed files
        CHANGED_FILES=$(git diff --name-only origin/main...HEAD)
        echo "Changed files:"
        echo "$CHANGED_FILES"
        
        # Check if code changes require documentation updates
        CODE_CHANGED=$(echo "$CHANGED_FILES" | grep -E '\.(py)$' | wc -l)
        DOCS_CHANGED=$(echo "$CHANGED_FILES" | grep -E '\.(md|rst|txt)$' | wc -l)
        
        echo "Code files changed: $CODE_CHANGED"
        echo "Documentation files changed: $DOCS_CHANGED"
        
        if [ "$CODE_CHANGED" -gt 5 ] && [ "$DOCS_CHANGED" -eq 0 ]; then
          echo "⚠️  Warning: Significant code changes detected without documentation updates"
          echo "Consider updating README.md, TESTING.md, or other relevant documentation"
        else
          echo "✓ Documentation check passed"
        fi

  # Job 8: Final Status Check
  ci-success:
    name: CI Success
    runs-on: ubuntu-latest
    needs: [code-quality, security, test, integration-test, build]
    if: always()
    
    steps:
    - name: Check all jobs status
      run: |
        echo "Job statuses:"
        echo "Code Quality: ${{ needs.code-quality.result }}"
        echo "Security: ${{ needs.security.result }}"
        echo "Test: ${{ needs.test.result }}"
        echo "Integration Test: ${{ needs.integration-test.result }}"
        echo "Build: ${{ needs.build.result }}"
        
        if [ "${{ needs.code-quality.result }}" != "success" ] || \
           [ "${{ needs.security.result }}" != "success" ] || \
           [ "${{ needs.test.result }}" != "success" ] || \
           [ "${{ needs.integration-test.result }}" != "success" ] || \
           [ "${{ needs.build.result }}" != "success" ]; then
          echo "❌ One or more critical jobs failed"
          exit 1
        else
          echo "✅ All critical jobs passed successfully"
        fi